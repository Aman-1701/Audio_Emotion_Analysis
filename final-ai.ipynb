{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"markdown","source":"# Helper Functions","metadata":{}},{"cell_type":"code","source":"def read_wav_file(path, file):\n    \n    data, samplerate = sf.read(path+file)\n    return data, samplerate \n\ndef display_waveplot(data, sr):\n    \n    plt.figure(figsize=(14, 5))\n    librosa.display.waveplot(data, sr=sr)\n    plt.grid()\n    plt.show()\n    \ndef plot_spectrogram(data, samplerate):\n    \n    sr = samplerate\n    spectrogram = librosa.feature.melspectrogram(data, sr=sr)\n    log_spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n    librosa.display.specshow(log_spectrogram, sr=sr, x_axis='time', y_axis='mel')\n    \n\nclass DataGenerator(Sequence):\n    def __init__(self, path, list_IDs, labels, batch_size):\n        self.path = path\n        self.list_IDs = list_IDs\n        self.labels = labels\n        self.batch_size = batch_size\n        self.indexes = np.arange(len(self.list_IDs))\n        self.data_lenght = 254000\n        self.num_labels = 8\n    \n    def __len__(self):\n        len_ = int(len(self.list_IDs)/self.batch_size)\n        if len_*self.batch_size < len(self.list_IDs):\n            len_ += 1\n        return len_\n    \n    def __getitem__(self, index):\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n        X, y = self.__data_generation(list_IDs_temp)\n        X = X.reshape((self.batch_size, 100, 2540//2))\n        return X, y\n    \n    def __data_generation(self, list_IDs_temp):\n        X = np.zeros((self.batch_size, self.data_lenght//2))\n        y = np.zeros((self.batch_size, self.num_labels))\n        for i, ID in enumerate(list_IDs_temp):\n            file = self.labels.loc[i, 'File']\n            actor = file.split('.')[0].split('-')[-1]\n            path_file = self.path+'Actor_'+str(actor+'/')\n            audio_file, audio_sr = read_wav_file(path_file, file)\n            lenght = len(audio_file)\n            audio_file_fft = np.abs(np.fft.fft(audio_file)[: lenght//2])\n            # scale data\n            audio_file_fft = (audio_file_fft-audio_file_fft.mean())/audio_file_fft.std()\n            X[i, :(lenght//2)] = audio_file_fft\n            y[i, ] = self.labels.loc[ID, self.labels.columns[:-1]].values\n        return X, y","metadata":{"execution":{"iopub.status.busy":"2021-11-10T06:10:09.495049Z","iopub.execute_input":"2021-11-10T06:10:09.495523Z","iopub.status.idle":"2021-11-10T06:10:09.512947Z","shell.execute_reply.started":"2021-11-10T06:10:09.495471Z","shell.execute_reply":"2021-11-10T06:10:09.511799Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"# Libraries\n","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport time\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nimport soundfile as sf\nimport librosa\nimport librosa.display\nimport IPython.display as display\n\nfrom keras.utils import Sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPool1D, BatchNormalization\nfrom keras.optimizers import RMSprop,Adam\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-11-10T06:10:09.514630Z","iopub.execute_input":"2021-11-10T06:10:09.515072Z","iopub.status.idle":"2021-11-10T06:10:09.529645Z","shell.execute_reply.started":"2021-11-10T06:10:09.515044Z","shell.execute_reply":"2021-11-10T06:10:09.528722Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"# Path","metadata":{}},{"cell_type":"code","source":"path = '/kaggle/input/ravdess-emotional-speech-audio/'\n#os.listdir(path)[0:2]","metadata":{"execution":{"iopub.status.busy":"2021-11-10T06:10:09.532616Z","iopub.execute_input":"2021-11-10T06:10:09.533236Z","iopub.status.idle":"2021-11-10T06:10:09.543327Z","shell.execute_reply.started":"2021-11-10T06:10:09.533195Z","shell.execute_reply":"2021-11-10T06:10:09.542509Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"# Labels","metadata":{}},{"cell_type":"code","source":"emotions = {1: 'neutral', 2: 'calm', 3: 'happy', 4: 'sad', 5: 'angry', 6: 'fearful', 7: 'disgust', 8: 'surprised'}","metadata":{"execution":{"iopub.status.busy":"2021-11-10T06:10:09.545242Z","iopub.execute_input":"2021-11-10T06:10:09.545764Z","iopub.status.idle":"2021-11-10T06:10:09.553063Z","shell.execute_reply.started":"2021-11-10T06:10:09.545710Z","shell.execute_reply":"2021-11-10T06:10:09.551942Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"# Overview\nThere are 24 actors. For each of the actores there are existing 60 wave files.\nWe create a data frame with all meta data informations:","metadata":{}},{"cell_type":"code","source":"actors = ['Actor_'+str(i).zfill(2) for i in range(1, 25)]","metadata":{"execution":{"iopub.status.busy":"2021-11-10T06:10:09.554255Z","iopub.execute_input":"2021-11-10T06:10:09.554510Z","iopub.status.idle":"2021-11-10T06:10:09.562475Z","shell.execute_reply.started":"2021-11-10T06:10:09.554486Z","shell.execute_reply":"2021-11-10T06:10:09.561526Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"columns = ['File', 'Modality', 'Vocal', 'Emotion', 'Intensity', 'Statement', 'Repetition', 'Actor']\ndf = pd.DataFrame(columns = columns)\nfiles = []\nfor actor in actors:\n    files.extend(os.listdir(path+actor))\ndf['File'] = files\nfile = files[0]\nfor i in range(len(files)):\n    file = files[i]\n    integer_list = list(map(int, file.split('.')[0].split('-')))\n    df.loc[i, df.columns[1:]] = integer_list\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-10T06:10:09.564152Z","iopub.execute_input":"2021-11-10T06:10:09.564628Z","iopub.status.idle":"2021-11-10T06:10:10.171618Z","shell.execute_reply.started":"2021-11-10T06:10:09.564542Z","shell.execute_reply":"2021-11-10T06:10:10.170738Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"# A Sample File\nWe take focus on the first sample of the data frame to show how to handle and interpret the file.\n\n\n","metadata":{}},{"cell_type":"code","source":"row = 0\nfile = df.loc[row, 'File']\npath_file = path+'Actor_'+str(df.loc[row, 'Actor']).zfill(2)+'/'\nfile","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-10T06:10:10.172950Z","iopub.execute_input":"2021-11-10T06:10:10.173306Z","iopub.status.idle":"2021-11-10T06:10:10.182489Z","shell.execute_reply.started":"2021-11-10T06:10:10.173269Z","shell.execute_reply":"2021-11-10T06:10:10.181675Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"display.Audio(path_file+file)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T06:10:10.183545Z","iopub.execute_input":"2021-11-10T06:10:10.183890Z","iopub.status.idle":"2021-11-10T06:10:10.205288Z","shell.execute_reply.started":"2021-11-10T06:10:10.183854Z","shell.execute_reply":"2021-11-10T06:10:10.204447Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# loading wave file\ndata, sr = read_wav_file(path_file, file)\nprint('Lenght Data Array:', len(data))\nprint('Samplerate:', sr)\nprint('Lenght Audio:', len(data)/sr)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T06:10:10.207983Z","iopub.execute_input":"2021-11-10T06:10:10.208374Z","iopub.status.idle":"2021-11-10T06:10:10.216606Z","shell.execute_reply.started":"2021-11-10T06:10:10.208332Z","shell.execute_reply":"2021-11-10T06:10:10.215845Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"# Waveplot","metadata":{}},{"cell_type":"code","source":"display_waveplot(data, sr)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T06:10:10.219353Z","iopub.execute_input":"2021-11-10T06:10:10.220015Z","iopub.status.idle":"2021-11-10T06:10:10.372568Z","shell.execute_reply.started":"2021-11-10T06:10:10.219975Z","shell.execute_reply":"2021-11-10T06:10:10.371778Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"## Spectogram ","metadata":{}},{"cell_type":"code","source":"plot_spectrogram(data, sr)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T06:10:10.373945Z","iopub.execute_input":"2021-11-10T06:10:10.374299Z","iopub.status.idle":"2021-11-10T06:10:10.620153Z","shell.execute_reply.started":"2021-11-10T06:10:10.374262Z","shell.execute_reply":"2021-11-10T06:10:10.619285Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"#We extend the data frame df by the features\n    # Lenght_Data_Array\n    # Samplerate\n\nfor row in df.index:\n    file = df.loc[row, 'File']\n    path_file = path+'Actor_'+str(df.loc[row, 'Actor']).zfill(2)+'/'\n    data, sr = read_wav_file(path_file, file)\n    df.loc[row, 'Lenght_Data_Array'] = len(data)\n    df.loc[row, 'Samplerate'] = sr\ndf['Seconds'] = df['Lenght_Data_Array']/df['Samplerate'] ","metadata":{"execution":{"iopub.status.busy":"2021-11-10T06:10:10.621655Z","iopub.execute_input":"2021-11-10T06:10:10.622015Z","iopub.status.idle":"2021-11-10T06:10:13.385840Z","shell.execute_reply.started":"2021-11-10T06:10:10.621975Z","shell.execute_reply":"2021-11-10T06:10:13.384951Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"# Data Analysis\nThe features emotion and intensity are not evenly distributed:","metadata":{}},{"cell_type":"code","source":"df['Emotion'].value_counts().sort_index()","metadata":{"execution":{"iopub.status.busy":"2021-11-10T06:10:13.387161Z","iopub.execute_input":"2021-11-10T06:10:13.387495Z","iopub.status.idle":"2021-11-10T06:10:13.395613Z","shell.execute_reply.started":"2021-11-10T06:10:13.387459Z","shell.execute_reply":"2021-11-10T06:10:13.394683Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"df['Intensity'].value_counts().sort_index()","metadata":{"execution":{"iopub.status.busy":"2021-11-10T06:10:13.397186Z","iopub.execute_input":"2021-11-10T06:10:13.397924Z","iopub.status.idle":"2021-11-10T06:10:13.409626Z","shell.execute_reply.started":"2021-11-10T06:10:13.397821Z","shell.execute_reply":"2021-11-10T06:10:13.408794Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"df['Statement'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-11-10T06:10:13.410857Z","iopub.execute_input":"2021-11-10T06:10:13.411278Z","iopub.status.idle":"2021-11-10T06:10:13.424996Z","shell.execute_reply.started":"2021-11-10T06:10:13.411238Z","shell.execute_reply":"2021-11-10T06:10:13.424228Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# Checking length of audio file\ndf['Seconds'].hist(bins=20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-10T06:10:13.427243Z","iopub.execute_input":"2021-11-10T06:10:13.427509Z","iopub.status.idle":"2021-11-10T06:10:13.575104Z","shell.execute_reply.started":"2021-11-10T06:10:13.427474Z","shell.execute_reply":"2021-11-10T06:10:13.574086Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"# Encoding Target Labels","metadata":{}},{"cell_type":"code","source":"labels= pd.DataFrame(0, index=df.index, columns=emotions.values())\nfor row in labels.index:\n    labels.loc[row, labels.columns[df.loc[row, 'Emotion']-1]]=1\nlabels['File'] = df['File']","metadata":{"execution":{"iopub.status.busy":"2021-11-10T06:10:13.576727Z","iopub.execute_input":"2021-11-10T06:10:13.577080Z","iopub.status.idle":"2021-11-10T06:10:13.711667Z","shell.execute_reply.started":"2021-11-10T06:10:13.577043Z","shell.execute_reply":"2021-11-10T06:10:13.710726Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"labels.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T06:10:13.714983Z","iopub.execute_input":"2021-11-10T06:10:13.715254Z","iopub.status.idle":"2021-11-10T06:10:13.731044Z","shell.execute_reply.started":"2021-11-10T06:10:13.715227Z","shell.execute_reply":"2021-11-10T06:10:13.730061Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"# Train - Test Split","metadata":{}},{"cell_type":"code","source":"list_IDs_train, list_IDs_val = train_test_split(list(df.index), test_size=0.33, random_state=2021)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T06:10:13.733671Z","iopub.execute_input":"2021-11-10T06:10:13.734283Z","iopub.status.idle":"2021-11-10T06:10:13.740232Z","shell.execute_reply.started":"2021-11-10T06:10:13.734245Z","shell.execute_reply":"2021-11-10T06:10:13.739274Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"#Using Data Generator to load the data on demand.\nbatch_size = 32\ntrain_generator = DataGenerator(path, list_IDs_train, labels, batch_size)\nval_generator = DataGenerator(path, list_IDs_val, labels, batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T06:10:13.741937Z","iopub.execute_input":"2021-11-10T06:10:13.742404Z","iopub.status.idle":"2021-11-10T06:10:13.750564Z","shell.execute_reply.started":"2021-11-10T06:10:13.742370Z","shell.execute_reply":"2021-11-10T06:10:13.749819Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"# Model Hyperparameters","metadata":{}},{"cell_type":"code","source":"epochs = 2\nlernrate = 1e-3","metadata":{"execution":{"iopub.status.busy":"2021-11-10T06:12:29.181125Z","iopub.execute_input":"2021-11-10T06:12:29.181444Z","iopub.status.idle":"2021-11-10T06:12:29.184992Z","shell.execute_reply.started":"2021-11-10T06:12:29.181412Z","shell.execute_reply":"2021-11-10T06:12:29.184136Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv1D(64, input_shape=(100, 2540//2,), kernel_size=5, strides=4, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool1D(pool_size=(4)))\nmodel.add(Conv1D(64, kernel_size=3, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Conv1D(64, kernel_size=3, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(8, activation='sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2021-11-10T06:13:21.071273Z","iopub.execute_input":"2021-11-10T06:13:21.071643Z","iopub.status.idle":"2021-11-10T06:13:21.173924Z","shell.execute_reply.started":"2021-11-10T06:13:21.071608Z","shell.execute_reply":"2021-11-10T06:13:21.173047Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = Adam(lr=lernrate),\n              loss='binary_crossentropy',\n              metrics=['binary_accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-11-10T06:18:49.925107Z","iopub.execute_input":"2021-11-10T06:18:49.925736Z","iopub.status.idle":"2021-11-10T06:18:50.021862Z","shell.execute_reply.started":"2021-11-10T06:18:49.925661Z","shell.execute_reply":"2021-11-10T06:18:50.016864Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-10T06:18:52.234067Z","iopub.execute_input":"2021-11-10T06:18:52.234688Z","iopub.status.idle":"2021-11-10T06:18:52.255555Z","shell.execute_reply.started":"2021-11-10T06:18:52.234624Z","shell.execute_reply":"2021-11-10T06:18:52.254328Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(generator=train_generator, validation_data=val_generator, epochs = epochs, workers=4)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T06:18:55.094436Z","iopub.execute_input":"2021-11-10T06:18:55.095079Z","iopub.status.idle":"2021-11-10T06:20:50.071693Z","shell.execute_reply.started":"2021-11-10T06:18:55.095001Z","shell.execute_reply":"2021-11-10T06:20:50.070875Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"markdown","source":"# Saving Model & Weights","metadata":{}},{"cell_type":"code","source":"model.save('[CNN]M.h5')\nmodel.save_weights('[CNN]W.h5')","metadata":{"execution":{"iopub.status.busy":"2021-11-10T06:12:07.527418Z","iopub.execute_input":"2021-11-10T06:12:07.529724Z","iopub.status.idle":"2021-11-10T06:12:07.758869Z","shell.execute_reply.started":"2021-11-10T06:12:07.529676Z","shell.execute_reply":"2021-11-10T06:12:07.753251Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"model_name = 'Model.h5'\nsave_dir = os.path.join(os.getcwd(), 'saved_models')\n\nif not os.path.isdir(save_dir):\n    os.makedirs(save_dir)\nmodel_path = os.path.join(save_dir, model_name)\nmodel.save(model_path)\nprint('Save model and weights at %s ' % model_path)\n\nmodel_json = model.to_json()\nwith open(\"model_json.json\", \"w\") as json_file:\n    json_file.write(model_json)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T06:12:07.765749Z","iopub.execute_input":"2021-11-10T06:12:07.766176Z","iopub.status.idle":"2021-11-10T06:12:07.897618Z","shell.execute_reply.started":"2021-11-10T06:12:07.766135Z","shell.execute_reply":"2021-11-10T06:12:07.896563Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":"# Traning Analysis","metadata":{}},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize=(16, 4))\nfig.subplots_adjust(hspace = .2, wspace=.2)\naxs = axs.ravel()\nloss = history.history['loss']\nloss_val = history.history['val_loss']\nepochs = range(1, len(loss)+1)\naxs[0].plot(epochs, loss, 'bo', label='loss_train')\naxs[0].plot(epochs, loss_val, 'ro', label='loss_val')\naxs[0].set_title('Value of the loss function')\naxs[0].set_xlabel('epochs')\naxs[0].set_ylabel('value of the loss function')\naxs[0].legend()\naxs[0].grid()\nacc = history.history['binary_accuracy']\nacc_val = history.history['val_binary_accuracy']\naxs[1].plot(epochs, acc, 'bo', label='accuracy_train')\naxs[1].plot(epochs, acc_val, 'ro', label='accuracy_val')\naxs[1].set_title('Accuracy')\naxs[1].set_xlabel('Epochs')\naxs[1].set_ylabel('Value of accuracy')\naxs[1].legend()\naxs[1].grid()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-10T06:22:27.959384Z","iopub.execute_input":"2021-11-10T06:22:27.959715Z","iopub.status.idle":"2021-11-10T06:22:28.277506Z","shell.execute_reply.started":"2021-11-10T06:22:27.959684Z","shell.execute_reply":"2021-11-10T06:22:28.276659Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"markdown","source":"# Test Accuracy\n","metadata":{}},{"cell_type":"code","source":"print(\"[INFO] Calculating model accuracy\")\nscores = model.evaluate(val_generator)\nprint(f\"Test Accuracy: {scores[1]*100}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-10T06:25:04.583473Z","iopub.execute_input":"2021-11-10T06:25:04.583846Z","iopub.status.idle":"2021-11-10T06:25:19.206960Z","shell.execute_reply.started":"2021-11-10T06:25:04.583812Z","shell.execute_reply":"2021-11-10T06:25:19.205880Z"},"trusted":true},"execution_count":82,"outputs":[]}]}